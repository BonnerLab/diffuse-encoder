{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with Diffusion Model\n",
    "\n",
    "This section is for people who haven't played with diffusion model before. Have fun!\n",
    "\n",
    "Materials which are helpful during this process. Here are helpful materials:\n",
    "\n",
    "- Math ideas: [Diffusion Models](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n",
    "- Follow the tutorial in Hugging Face: [Using Diffusers](https://huggingface.co/docs/diffusers/using-diffusers/write_own_pipeline)\n",
    "- Web UI: [A Flexible Platform](https://github.com/AUTOMATIC1111/stable-diffusion-webui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages required\n",
    "import torch\n",
    "from PIL import Image\n",
    "# Load the diffusion model for text2img and img2img\n",
    "from diffusers import StableDiffusionPipeline,StableDiffusionImg2ImgPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on GPU\n",
    "device = \"cuda\"\n",
    "# Set a seed for PyTorch\n",
    "torch.manual_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stable-diffusion v1.5\n",
    "model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "# Feel free to turn on safety_checker\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id_or_path, safety_checker=None,torch_dtype=torch.float16)\n",
    "pipe.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first part is to create two base images for our analysis. Feel free to change prompts you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "prompt = ['a dog','a cat']\n",
    "# How much we weight for text2img, default: 7.5\n",
    "# To which extent, we hope that our image is closed to text measrued by CLIP\n",
    "# Feel free to play to play with guidance scale between $[1,\\infty]$\n",
    "guidance_scale = 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images generated by pipe\n",
    "# from a pure gaussian noise to images\n",
    "images = pipe(prompt=prompt,guidance_scale=guidance_scale).images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images, feel free to comment out if you want to use image provided\n",
    "images[0].save('dog+.jpg')\n",
    "images[1].save('cat+.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with negative guidance scale\n",
    "images_negative = pipe(prompt=prompt,guidance_scale=-guidance_scale).images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images, feel free to comment out if you want to use image provided\n",
    "images_negative[0].save('dog-.jpg')\n",
    "images_negative[1].save('cat-.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the view of CLIP model, you can find that it doesn't capture semantic opposite structure such as cat and dog. It seems that CLIP captures covariance instead of some strict work embedding relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The second part is to do img2img variations on base images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base images\n",
    "dog_image = Image.open('dog+.jpg')\n",
    "cat_image = Image.open('cat+.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load img2img pipeline\n",
    "torch.cuda.empty_cache()\n",
    "pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, safety_checker=None,torch_dtype=torch.float16)\n",
    "pipe_img2img.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set where we start to remove noises,\n",
    "# The value is between 0 and 1. If 1, we totally ignore the image\n",
    "# default: 0.8\n",
    "strength = 0.8\n",
    "# Set how strong we condition on prompt\n",
    "guidance_scale = 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image variations for dog\n",
    "# + Image + Text\n",
    "dog_images_pp = pipe_img2img(prompt = 'a dog',image = dog_image, strength =strength,\n",
    "                                     guidance_scale = guidance_scale,num_images_per_prompt=1).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see some random change has been updated\n",
    "# Feel free to change the value of strength to see what happens\n",
    "dog_images_pp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + Image - Text\n",
    "dog_images_pn = pipe_img2img(prompt='',negative_prompt = 'a dog',image = dog_image, strength =strength,\n",
    "                                     guidance_scale = guidance_scale,num_images_per_prompt=1).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_images_pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine that we don't use the default negative_prompt in diffusion\n",
    "# However, we offer a prompt which is negatove in human perspective\n",
    "dog_images_pn_human = pipe_img2img(prompt='a cat',image = dog_image, strength =0.8,\n",
    "                             guidance_scale = guidance_scale,num_images_per_prompt=1).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_images_pn_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -Image +prompt\n",
    "dog_images_pn = pipe_img2img(prompt = 'a dog',image = cat_image, strength = strength,\n",
    "                                     guidance_scale = guidance_scale,num_images_per_prompt=1).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_images_pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Image -Prompt\n",
    "dog_images_nn = pipe_img2img(prompt ='',negative_prompt='a dog',image = cat_image, strength = strength,\n",
    "                                     guidance_scale = guidance_scale,num_images_per_prompt=1).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_images_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The third part is to add a controlnet section to see how we can preserve particular information from original image and do some random change. Here, we take edge as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get edge by canny edge detection ad conditions\n",
    "low_threshold = 100\n",
    "high_threshold = 200\n",
    "\n",
    "canny_edge = cv2.Canny(np.array(dog_image), low_threshold, high_threshold)\n",
    "canny_edge = canny_edge[:, :, None]\n",
    "canny_edge  = np.concatenate([canny_edge,canny_edge,canny_edge], axis=2)\n",
    "canny_edge = Image.fromarray(canny_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "        \"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe_canny = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, safety_checker=None, torch_dtype=torch.float16\n",
    ")\n",
    "pipe_canny.scheduler = UniPCMultistepScheduler.from_config(pipe_canny.scheduler.config)\n",
    "pipe_canny.enable_xformers_memory_efficient_attention()\n",
    "pipe_canny.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We off both canny edge and text\n",
    "dog_images_canny = pipe_canny('a dog',image=canny_edge,num_inference_steps=20,num_images_per_prompt=1).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_images_canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on edge information, let the model to guess\n",
    "dog_images_canny_guess = pipe_canny(\"\",image=canny_edge,num_inference_steps=20,num_images_per_prompt=1,guess_mode=True, guidance_scale=3.0).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_images_canny_guess "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuse-encoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
